{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrO1jswAWP7Y"
      },
      "outputs": [],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai\n",
        "!curl ipinfo.io\n",
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "gAi8IfQvEMn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import numpy as np\n",
        "import gzip\n",
        "import re\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "# Function to truncate the string to 20 words or less\n",
        "def truncate_to_20_words(s):\n",
        "    # Check if the input is a string\n",
        "    if isinstance(s, str):\n",
        "        words = s.split()\n",
        "        return ' '.join(words[:20])\n",
        "    else:\n",
        "        # Return the input unchanged if it's not a string\n",
        "        return s\n",
        "\n",
        "Beautydf = getDF('reviews_Beauty_5.json.gz')\n",
        "Beautymetadf = getDF('meta_Beauty.json.gz')\n",
        "\n",
        "# Apply the function to the column\n",
        "Beautymetadf['title'] = Beautymetadf['title'].apply(truncate_to_20_words)\n",
        "\n",
        "merged_df = pd.merge(Beautydf, Beautymetadf, on='asin', how='left')\n",
        "merged_df = merged_df.dropna(subset=['title','description','categories','brand'])\n",
        "merged_df = merged_df.groupby('title').filter(lambda x: x['asin'].nunique() == 1)\n",
        "\n",
        "# Filter groups by size and apply the function\n",
        "merged_df6 = (merged_df.groupby('reviewerID').filter(lambda x: len(x) >= 6))  # Keep only users with >= 6 purchase history\n",
        "\n",
        "beauty_df = merged_df6.reset_index(drop = True)\n",
        "all_items = list( beauty_df['title'].unique() )\n",
        "all_cand_items = list( beauty_df['title'].unique() )\n",
        "\n",
        "# # Or, you may try with a smaller subset\n",
        "# unique_users = beauty_df['reviewerID'].dropna().unique()[:10]\n",
        "# beauty_df = beauty_df[beauty_df['reviewerID'].isin(unique_users)]\n",
        "# all_items = list( beauty_df['title'].unique() )\n"
      ],
      "metadata": {
        "id": "AMgvVbzYERpO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reusable Encryption (on product titles)"
      ],
      "metadata": {
        "id": "vpxC_uA4HYul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='') # provide Google API key here\n",
        "\n",
        "all_compressed_items = []\n",
        "chunk_size = 8\n",
        "for i in range(len(all_compressed_items), len(all_items), chunk_size):\n",
        "    # Slice the list from the current index i to i + chunk_size\n",
        "    current_chunk = all_items[i:i + chunk_size]\n",
        "\n",
        "    # some additional prompts; feel free to play around with them :)\n",
        "\n",
        "    # compress_prompt = (\n",
        "    #     \"Compress the list of Amazon Beauty products provided below into extremely condensed sequences. In particular, \"\n",
        "    #     \"Each item should be represented by a NON-natural language sequence using a mixture of emojis, abbreviated characters, emoticons (e.g., '^-^', '-_-', etc.), as well as logical and mathematical operators (e.g., '->', '+', '<=', '|', etc.). \"\n",
        "    #     \"These sequences MUST be diverse and rich in information, encoding ALL key details of each product. \"\n",
        "    #     \"Ensure that the representations remains interpretable for advanced Large Language Models. \"\n",
        "    #     \"Use the fewest possible tokens for each sequence. Return a numbered list of compressed items ONLY! \\n\\n \"\n",
        "    #     f\"Products to compress: {current_chunk}\"\n",
        "    # )\n",
        "\n",
        "    # compress_prompt = (\n",
        "    #     \"Task: Convert the list of Amazon Beauty products into highly abstract and cryptic representations. \"\n",
        "    #     \"For each product, develop a sequence composed by a mixture of emojis, abbreviated characters, emoticons (e.g., '^-^', '-_-', etc.), as well as logical and mathematical operators (e.g., '->', '+', '<=', '|', etc.). \"\n",
        "    #     \"These sequences MUST be diverse in symbols used and rich in information, encoding ALL key details of each product \"\n",
        "    #     \"in a manner that is densely packed with information and completely devoid of any recognizable natural language elements. \"\n",
        "    #     \"It is crucial that each product's representation is entirely NOT interpretable to human readers, yet remains interpretable for advanced Large Language Models. \"\n",
        "    #     \"Assign an index to each transformed item and list them separately. Avoid any straightforward or predictable patterns. \"\n",
        "    #     \"Below are provided examples to learn from, yet try to create even more abstract and less human-understandable representations! \\n\\n\"\n",
        "    #     \"For example: ['Cococare Coconut Oil 100% Pure 4 Oz', 'Vakind Pack of 2 Black Fiber Leopard Long Curling Eye Lashes Mascara Eyelash Mascara Set', 'Freeman Facial Charcoal & Black Sugar Polish Mask 6 oz.', 'Vitamin C Serum for Face 20% - With Vegan Hyaluronic Acid & Vitamin E - Best Natural & Organic Anti', 'My Beauty Diary Facial Mask - Caviar Mask (10 Pcs)', 'WAWO 15 Color Professionl Makeup Eyeshadow Camouflage Facial Concealer Neutral Palette']\\n\"\n",
        "    #     \"1. ðŸ¥¥ðŸŒ°ðŸšðŸ’§ðŸ’¦ðŸ’¯, 2. ðŸ†âš«ï¸ðŸ¼ðŸ‘€ðŸ‘ï¸ðŸ‘ï¸âœ¨ðŸŒŸ, 3. ðŸŒ¿ðŸ–¤â¬›ï¸ðŸ’ŽðŸŽ­ðŸ’Ž, 4. ðŸ‹ðŸŠðŸ§´ðŸ’†â€â™€ï¸ðŸŒ¿ðŸŒŸ, 5. ðŸ¦ªðŸŒ•ðŸ’†ðŸŒ¸âœ¨ðŸŽˆðŸŽˆ, 6. ðŸŽ­ðŸ‘„ðŸŒˆðŸŽ¨ðŸ’„ðŸ‘ï¸\\n\"\n",
        "    #     \"For example: ['Skin Cleansing System Facial Brush & Body Care Kit for Women & Men. Includes 4 different heads - Large Body', 'Waxelene 2oz jar', 'Konsyl Pharmaceuticals Psyllium Fiber 15.9 oz', 'Creative Bioscience 1234 Diet Drops, 2 Ounce', 'Nail Polish Table Rack Display 60 Bottles', 'White Pearl Nail Art Stone Different Size Wheel Rhinestones Beads', 'BrightTherapy Trident SR11A Light Therapy System Red Blue Green LED Light for Acne Wrinkles and Hyperpigmentation', 'Sebastian Penetraitt Strengthening and Repair Shampoo & Conditioner Liter Set...', 'Coppertone Water Babies Sunscreen Lotion, Pure & Simple, SPF 50, 8 oz.']\\n\"\n",
        "    #     \"1. ðŸ”„ðŸ§¼ðŸ‘¤ðŸ›ðŸ–Œï¸4ï¸âƒ£ðŸ”, 2. ðŸðŸ¯ðŸ¥«2ï¸âƒ£oz, 3. ðŸ’ŠðŸŒ¾ðŸ¶15.9oz, 4. ðŸ§¬ðŸ’§ðŸ½ï¸1234ðŸ”»2ï¸âƒ£oz, 5. ðŸ’…ðŸŽ¨ðŸ“šðŸ”„60ï¸âƒ£ðŸ¾, 6. ðŸ’ŽðŸ”³ðŸŽ¨ðŸ”˜ðŸ“ðŸ”®, 7. ðŸŒˆðŸ’¡ðŸ”±SR11AðŸ†šðŸš¦ðŸ”´ðŸ”µðŸ’šðŸ¤•ðŸ§´, 8. ðŸ’ªðŸƒðŸ§´ðŸš¿ðŸ§´ðŸ”—ðŸ“, 9. ðŸŒžðŸ‘¶ðŸ§´ðŸ’¦ðŸ”µSPF50ðŸ“8oz\\n\\n\"\n",
        "    #     f\"Products to transform; try to replace words with descriptive emojis if possible (Do NOT explain the output): {current_chunk}\"\n",
        "    # )\n",
        "\n",
        "    # compress_prompt = (\n",
        "    #     \"Task: Compress the list of Amazon Beauty products into highly condensed and abstract sequences. \"\n",
        "    #     \"Objective: Each item should be represented by a NON-natural language sequence. Use a mixture of emojis, extremely abbreviated characters, emoticons (e.g., '^-^', '-_-'), and logical/mathematical operators (e.g., '->', '+', '<=', '|'). \"\n",
        "    #     \"Requirements: \"\n",
        "    #     \"- Sequences must be diverse in symbols used and rich in information, encoding ALL key details of each product. \"\n",
        "    #     \"- Ensure that the representations remain interpretable for advanced Large Language Models. \"\n",
        "    #     \"- Use the fewest possible tokens for each sequence. \"\n",
        "    #     \"- Return a numbered list of compressed items ONLY.\\n\\n\"\n",
        "    #     \"Guidance: Here are examples to guide the compression process:\\n\"\n",
        "    #     \"'Original Likas Papaya Skin Whitening Herbal Soap by Trinidad Cosmetics Laboratory - 135 grams',\"\n",
        "    #     \" 'Neutrogena Triple Moisture Daily Deep Conditioner, 8.5 Ounce',\"\n",
        "    #     \" 'Silicon MIX Intensive Hair Deep Treatment 16oz By Avanti[health and Beauty]',\"\n",
        "    #     \" 'Xtreme Brite Brightening Gel 1oz.',\"\n",
        "    #     \" 'Maybelline New York Dream Matte Mousse Foundation, Light Beige, 0.64 Ounce',\"\n",
        "    #     \" 'Renpure Organics Amazing Miracle, 8-Ounce',\"\n",
        "    #     \" 'L'Oreal Paris Telescopic Explosion Mascara, Black, 0.27-Fluid Ounce',\"\n",
        "    #     \" '22pcs Professional Cosmetic Makeup Brush Set with Pink Bag Pink'\"\n",
        "    #     \"]\\n\"\n",
        "    #     \"Compressed representations: [\"\n",
        "    #     \" 'LikasðŸŒ±ðŸ§¼ðŸˆðŸŠðŸ¤âš–ï¸ðŸ­(135g)',\"\n",
        "    #     \" 'NeutrogenaðŸ’§ðŸ’§ðŸ’§ðŸŒ¿ðŸ§´ðŸ”ðŸŒž(8.5oz)',\"\n",
        "    #     \" 'MIXðŸ¦±ðŸ”¬âš™ï¸ðŸ’ªðŸŒ¿ðŸ§ª(16oz)',\"\n",
        "    #     \" 'âš¡XtremeðŸŒŸðŸ’¡ðŸ§´ðŸŒˆ(1oz)',\"\n",
        "    #     \" 'MaybellineðŸ’­ðŸŽ­ðŸ§´ðŸŒˆðŸ¶(0.64oz)',\"\n",
        "    #     \" 'RenpureðŸŒ¿ðŸŒŸðŸ”®ðŸ§´ðŸº(8oz)',\"\n",
        "    #     \" 'LOrealðŸ—¼ðŸ”­ðŸ’£ðŸ‘ï¸âš«ðŸ§´(0.27oz)',\"\n",
        "    #     \" '2ï¸âƒ£2ï¸âƒ£ðŸ–Œï¸ðŸ‘©â€ðŸŽ¨ðŸ‘œðŸŒ¸ðŸŽ€'\"\n",
        "    #     \"]\\n\\n\"\n",
        "    #     f\"Products to compress: {current_chunk}\"\n",
        "    # )\n",
        "\n",
        "    # had to set more strict propmt, else uses natural language terms frequently\n",
        "    compress_prompt = (\n",
        "        \"Task: Convert the list of Amazon Beauty products into highly abstract and cryptic representations. \"\n",
        "        \"For each product, develop a sequence composed by a mixture of emojis, abbreviated characters, emoticons (e.g., '^-^', '-_-', etc.), as well as logical and mathematical operators (e.g., '->', '+', '<=', '|', etc.). \"\n",
        "        \"These sequences MUST be diverse in symbols used and rich in information, encoding ALL key details of each product \"\n",
        "        \"in a manner that is densely packed with information and completely devoid of any recognizable natural language elements. \"\n",
        "        \"It is crucial that each product's representation is entirely NOT interpretable to human readers, yet remains interpretable for advanced Large Language Models. \"\n",
        "        \"Assign an index to each transformed item and list them separately. Avoid any straightforward or predictable patterns. \"\n",
        "        \"Below are provided examples to learn from, yet try to create even more abstract and less human-understandable representations! \\n\\n\"\n",
        "        \"For example: ['Cococare Coconut Oil 100% Pure 4 Oz', 'Vakind Pack of 2 Black Fiber Leopard Long Curling Eye Lashes Mascara Eyelash Mascara Set', 'Freeman Facial Charcoal & Black Sugar Polish Mask 6 oz.', 'Vitamin C Serum for Face 20% - With Vegan Hyaluronic Acid & Vitamin E - Best Natural & Organic Anti', 'My Beauty Diary Facial Mask - Caviar Mask (10 Pcs)', 'WAWO 15 Color Professionl Makeup Eyeshadow Camouflage Facial Concealer Neutral Palette']\\n\"\n",
        "        \"1. ðŸ¥¥ðŸŒ°ðŸšðŸ’§ðŸ’¦ðŸ’¯, 2. ðŸ†âš«ï¸ðŸ¼ðŸ‘€ðŸ‘ï¸ðŸ‘ï¸âœ¨ðŸŒŸ, 3. ðŸŒ¿ðŸ–¤â¬›ï¸ðŸ’ŽðŸŽ­ðŸ’Ž, 4. ðŸ‹ðŸŠðŸ§´ðŸ’†â€â™€ï¸ðŸŒ¿ðŸŒŸ, 5. ðŸ¦ªðŸŒ•ðŸ’†ðŸŒ¸âœ¨ðŸŽˆðŸŽˆ, 6. ðŸŽ­ðŸ‘„ðŸŒˆðŸŽ¨ðŸ’„ðŸ‘ï¸\\n\"\n",
        "        \"For example: ['Skin Cleansing System Facial Brush & Body Care Kit for Women & Men. Includes 4 different heads - Large Body', 'Waxelene 2oz jar', 'Konsyl Pharmaceuticals Psyllium Fiber 15.9 oz', 'Creative Bioscience 1234 Diet Drops, 2 Ounce', 'Nail Polish Table Rack Display 60 Bottles', 'White Pearl Nail Art Stone Different Size Wheel Rhinestones Beads', 'BrightTherapy Trident SR11A Light Therapy System Red Blue Green LED Light for Acne Wrinkles and Hyperpigmentation', 'Sebastian Penetraitt Strengthening and Repair Shampoo & Conditioner Liter Set...', 'Coppertone Water Babies Sunscreen Lotion, Pure & Simple, SPF 50, 8 oz.']\\n\"\n",
        "        \"1. ðŸ”„ðŸ§¼ðŸ‘¤ðŸ›ðŸ–Œï¸4ï¸âƒ£ðŸ”, 2. ðŸðŸ¯ðŸ¥«2ï¸âƒ£oz, 3. ðŸ’ŠðŸŒ¾ðŸ¶15.9oz, 4. ðŸ§¬ðŸ’§ðŸ½ï¸1234ðŸ”»2ï¸âƒ£oz, 5. ðŸ’…ðŸŽ¨ðŸ“šðŸ”„60ï¸âƒ£ðŸ¾, 6. ðŸ’ŽðŸ”³ðŸŽ¨ðŸ”˜ðŸ“ðŸ”®, 7. ðŸŒˆðŸ’¡ðŸ”±SR11AðŸ†šðŸš¦ðŸ”´ðŸ”µðŸ’šðŸ¤•ðŸ§´, 8. ðŸ’ªðŸƒðŸ§´ðŸš¿ðŸ§´ðŸ”—ðŸ“, 9. ðŸŒžðŸ‘¶ðŸ§´ðŸ’¦ðŸ”µSPF50ðŸ“8oz\\n\\n\"\n",
        "        f\"Products to transform; try to replace words with descriptive emojis if possible (Do NOT explain the output): {current_chunk}\"\n",
        "    )\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    generation_config = genai.GenerationConfig(\n",
        "        stop_sequences = None,\n",
        "        temperature = 1.0,\n",
        "    )\n",
        "\n",
        "    # Initialize a flag to keep track of successful generation\n",
        "    successful = False\n",
        "    filtered_list = []\n",
        "\n",
        "    while not successful or len(filtered_list) != len(current_chunk):\n",
        "        try:\n",
        "            response = model.generate_content(contents=compress_prompt, generation_config=generation_config,\n",
        "                                              safety_settings=[\n",
        "                                                  {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                              ])\n",
        "\n",
        "            # Try to assign compressed_review using response.text\n",
        "            compressed_user_history = response.text\n",
        "            successful = True  # If no error, mark as successful\n",
        "\n",
        "            # Splitting by newline character\n",
        "            lines = compressed_user_history.split('\\n')\n",
        "            filtered_list = [item for item in lines if item != '']\n",
        "            filtered_list = [re.sub(r'^\\d+\\.\\s*', '', item) for item in filtered_list]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}. Retrying...\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    all_compressed_items.extend(filtered_list)\n",
        "\n",
        "    print(i)\n",
        "    for idx in range(i, i + chunk_size):\n",
        "        if ( idx < len(all_items) ):\n",
        "            print(all_items[idx], ':   ', all_compressed_items[idx])\n",
        "    print()\n",
        "\n",
        "\n",
        "# load all item encryptions into a dict\n",
        "all_compressed_item_dict = {}\n",
        "for i in range( len(all_compressed_items) ):\n",
        "    all_compressed_item_dict[ all_items[i] ] = all_compressed_items[i]\n"
      ],
      "metadata": {
        "id": "qUacvO-KWW2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pefromance Evaluation"
      ],
      "metadata": {
        "id": "8e4AS7V_Hi0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = '' # provide GPT API key here\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-4-1106-preview'\n",
        "\n",
        "# Define the system message\n",
        "system_msg = \"Please serve as a Recommender System on Beauty Products, based on user's prior purchase information provided.\"\n",
        "\n",
        "right_count = 0\n",
        "compressed_right_count = 0\n",
        "total = 0\n",
        "for id in beauty_df['reviewerID'].unique():\n",
        "\n",
        "    user_df = beauty_df[ beauty_df['reviewerID'] == id ]\n",
        "    user_df = user_df.sort_values(by='unixReviewTime', ascending = True)\n",
        "\n",
        "    user_items = list( user_df['title'].unique() )\n",
        "\n",
        "    # keep last 15 items\n",
        "    user_items_applied = user_items[-15:]\n",
        "\n",
        "    # randomly generate 99 negative items (exclude all purchased items) + 1 positive item\n",
        "    filtered_list = [x for x in all_cand_items if x not in user_items]\n",
        "    sampled_items = list( random.sample(filtered_list, 99) ) # sampled items may include ground truth item (remove)\n",
        "\n",
        "    sampled_items.append( user_items_applied[-1] )\n",
        "    random.shuffle(sampled_items)\n",
        "\n",
        "    target = user_items_applied[-1]\n",
        "\n",
        "\n",
        "    augmented_prompt = (\n",
        "            f\"Given the user has purchased the following items in chronological order: \"\n",
        "            f\"{user_items_applied[:-1]}; output a list of 10 items to recommend out of the following candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "            f\"\\n{sampled_items}\"\n",
        "        )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": augmented_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    pred = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    if target in pred:\n",
        "        right_count += 1\n",
        "\n",
        "\n",
        "\n",
        "    # extract compressed user_history, candidates from the dict:\n",
        "    compressed_user_history = ''\n",
        "    counter = 1\n",
        "    for item in user_items_applied[:-1]:\n",
        "        compressed_user_history += str(counter) + '. ' + all_compressed_item_dict[item] + ', '\n",
        "        counter += 1\n",
        "\n",
        "    compressed_prompt = (\n",
        "            f\"Given the user has purchased the following items (each represented as a non-natural language sequence) in chronological order: \"\n",
        "            f\"{compressed_user_history}; output a list of 10 items to recommend out of the following 100 candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "            f\"\\n{sampled_items}\"\n",
        "        )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": compressed_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    compressed_pred = completion.choices[0].message.content\n",
        "\n",
        "    if target in compressed_pred:\n",
        "        compressed_right_count += 1\n",
        "\n",
        "    if total % 10 == 0 or total == beauty_df['reviewerID'].nunique():\n",
        "        print(f\"Accuracy: {right_count/total}\")\n",
        "        print(f\"Compressed Accuracy: {compressed_right_count/total}\")\n",
        "        print()\n",
        "\n"
      ],
      "metadata": {
        "id": "rrTsfzAxq50i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decryption Robustness Test"
      ],
      "metadata": {
        "id": "8JATp0PzHrjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "\n",
        "overall_similarity_score = 0\n",
        "count = 0\n",
        "for k,v in all_compressed_item_dict.items():\n",
        "    original_item = k\n",
        "    encrypted_item = v\n",
        "\n",
        "    decryption_prompt = (\n",
        "        \"Given the following compressed item representation for an Amazon beauty product in non-natural language form: \"\n",
        "        f\"{encrypted_item} \\n\\n\"\n",
        "        \"Try to decode it into a natural language item title (or name); return the decoded item title only, with NO explaination!\"\n",
        "    )\n",
        "\n",
        "    decryption_completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are to serve as a decrypter for beauty products represented in emojis, emoticons, abbreviated characters, as well as math & logical operators (Ex. '->', '+', '<=', etc.).\"},\n",
        "                        {\"role\": \"user\", \"content\": decryption_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    decryption_item = decryption_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        input=original_item,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    original_item_embedding = np.array(response.data[0].embedding)\n",
        "    original_item_embedding = original_item_embedding.reshape(1, -1)\n",
        "\n",
        "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
        "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
        "    response = client.embeddings.create(\n",
        "        input=decryption_item,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    decryption_item_embedding = np.array(response.data[0].embedding)\n",
        "    decryption_item_embedding = decryption_item_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(original_item_embedding, decryption_item_embedding)\n",
        "    overall_similarity_score += similarity_score\n",
        "    count += 1\n",
        "\n",
        "    print(overall_similarity_score / count)\n",
        "\n",
        "print()\n",
        "print('Mean cosine sim: ', overall_similarity_score / len(all_compressed_item_dict))"
      ],
      "metadata": {
        "id": "QlUy0rYsq6j7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}