{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIcApZk7_K6s"
      },
      "outputs": [],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "!pip install bert_score\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing:"
      ],
      "metadata": {
        "id": "tUXjx-FZVwRV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGQAANCJ_LNK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "census_df = pd.read_csv('census_small.csv', header = None)\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
        "                'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Assign the column names to the DataFrame\n",
        "census_df.columns = column_names\n",
        "census_df.fillna('Unknown')\n",
        "\n",
        "print( census_df['income'].unique() )\n",
        "census_df['income'] = census_df['income'].replace(' <=50K', 'no')\n",
        "census_df['income'] = census_df['income'].replace(' >50K', 'yes')\n",
        "census_df.drop(columns=['fnlwgt', 'education-num'], inplace=True)\n",
        "print( census_df['income'].unique() )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reusable Encryption (on feature levels)"
      ],
      "metadata": {
        "id": "VSYnDCksWG4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sri7Iqi1AVfC"
      },
      "outputs": [],
      "source": [
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-4-1106-preview'\n",
        "\n",
        "feature_level_dict = {}\n",
        "for column in census_df.columns[:-1]:  # Exclude the discretized column for this part\n",
        "    unique_values = census_df[column].unique()\n",
        "    for value in unique_values:\n",
        "        feature_level_to_convert = (f\"Feature: {column}, Value: {value}\")\n",
        "        print(feature_level_to_convert)\n",
        "\n",
        "        compression_prompt = (\n",
        "            f\"Analyze the feature and value: {feature_level_to_convert}. \"\n",
        "            \"Create a sequence using NON-natural language elements to depict the feature-value pair provided above. \"\n",
        "            \"Key guidelines: \"\n",
        "            \"- Avoid directly mentioning the feature or its value. Instead, use symbolic representation to represent the feature value precisely! \"\n",
        "            \"- Utilize a mix of abbreviated characters, emojis, emoticons, and logical/math operators (e.g., '->', '+', '<='). \"\n",
        "            \"- Aim for clarity and simplicity, ensuring the sequence is interpretable by advanced LLMs. Example: if feature and value = 'Feature: age, Value: 39', then the LLM need to be able to recognize it after sequence conversion.\"\n",
        "            \"- Present your sequence as a single line, optimizing for diversity in symbols while minimizing token usage. \"\n",
        "            \"Example (for illustration ONLY): For 'Feature: gender, Value: female', you might write: ðŸ‘©. \"\n",
        "            \"Important: Avoid directly mentioning the feature or its value in the output sequence!\"\n",
        "        )\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 1.0, max_tokens = 10,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please come up with a NON-natural language sequence for the narrative provided'},\n",
        "                        {\"role\": \"user\", \"content\": compression_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "        compressed_description = completion.choices[0].message.content\n",
        "        print(compressed_description)\n",
        "        print()\n",
        "\n",
        "        feature_level_dict[feature_level_to_convert] = compressed_description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation"
      ],
      "metadata": {
        "id": "9tUcGqkMYesz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeHTLjvuBNpa"
      },
      "outputs": [],
      "source": [
        "system_msg = \"Please serve as a binary classifier on user income level.\"\n",
        "\n",
        "right_count_pos = 0\n",
        "right_count_neg = 0\n",
        "compressed_right_count_pos = 0\n",
        "compressed_right_count_neg = 0\n",
        "total_pos = 0\n",
        "total_neg = 0\n",
        "total = 0\n",
        "\n",
        "# you may also set range smaller for a subset\n",
        "for i in range( len(census_df) ):\n",
        "    row_series = census_df.iloc[i][:-1]\n",
        "    target = census_df.iloc[i]['income']\n",
        "\n",
        "    overall_feature_levels = ''\n",
        "    converted_feature_levels = ''\n",
        "    for feature, value in row_series.items():\n",
        "        feature_level = (f\"Feature: {feature}, Value: {value}\")\n",
        "\n",
        "        overall_feature_levels += feature_level + '; '\n",
        "        converted_feature_levels += (f\"Feature: {feature}, Value: {feature_level_dict[feature_level]}\") + '; '\n",
        "\n",
        "    print(overall_feature_levels)\n",
        "    print(converted_feature_levels)\n",
        "    print()\n",
        "\n",
        "    original_prompt = (\n",
        "        f\"Given the following user description: \\n\\n {overall_feature_levels}; \\n\\n\"\n",
        "        f\"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'yes' or 'no', in lower case:\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": original_prompt }],\n",
        "            timeout = 1200)\n",
        "\n",
        "    original_pred = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    if target == 'yes':\n",
        "        total_pos += 1\n",
        "    else:\n",
        "        total_neg += 1\n",
        "\n",
        "    if target == original_pred:\n",
        "        if (target == 'yes'):\n",
        "            right_count_pos += 1\n",
        "        else:\n",
        "            right_count_neg += 1\n",
        "\n",
        "    census_prompt = (\n",
        "        \"You are given an user description with each feature value presented as a compressed NON-natural language sequence, \"\n",
        "        \"utilizing a mix of abstract & abbreviated characters, emojis, emoticons, as well as math & logical operators. \"\n",
        "        \"This sequence encapsulates the essential information of the user's original feature value. \"\n",
        "        \"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'yes' or 'no', in lower case, \"\n",
        "        \"Below is the compressed user description: \\n\\n\"\n",
        "        f\"{converted_feature_levels}\"\n",
        "    )\n",
        "\n",
        "    compressed_completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": census_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    compressed_pred = compressed_completion.choices[0].message.content\n",
        "\n",
        "    if target == compressed_pred:\n",
        "        if (target == 'yes'):\n",
        "            compressed_right_count_pos += 1\n",
        "        else:\n",
        "            compressed_right_count_neg += 1\n",
        "\n",
        "    if total % 10 == 0 or total == census_df.shape[0]:\n",
        "        print(f\"Accuracy: { (right_count_pos/total_pos) * 0.5 + (right_count_neg/total_neg) * 0.5 }\")\n",
        "        print(f\"Compressed Accuracy: { (compressed_right_count_pos/total_pos) * 0.5 + (compressed_right_count_neg/total_neg) * 0.5 }\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decryption Robustness Test"
      ],
      "metadata": {
        "id": "u8AvTFOLZLbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform feature value decryptions\n",
        "enc_dec_pairs = {}\n",
        "for k, v in feature_level_dict.items():\n",
        "    feature = k.split(', V')[0]\n",
        "    print(feature, v)\n",
        "\n",
        "    decryption_prompt = f\"Given the {feature}, and the non-natural language sequence: '{v}' that represents a value of the {feature} feature given, please try to decode the value. Return the decoded value only, in lower case and on a new line.\"\n",
        "    print(decryption_prompt)\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please serve as a feature value decrypter for the encrypted value given'},\n",
        "                        {\"role\": \"user\", \"content\": decryption_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    decryption = completion.choices[0].message.content\n",
        "\n",
        "    enc_dec_pairs[k] = feature + \", Value: \" + decryption\n",
        "    print(k, ' ', enc_dec_pairs[k])\n",
        "    print()\n",
        "\n",
        "\n",
        "# perform cos sim computations\n",
        "overall_similarity_score = 0\n",
        "for k, v in enc_dec_pairs.items():\n",
        "    original_level = k.split(', Value: ')[1]\n",
        "    decryption_level = v.split(', Value: ')[1]\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        input=original_level,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    original_level_embedding = np.array(response.data[0].embedding)\n",
        "    original_level_embedding = original_level_embedding.reshape(1, -1)\n",
        "\n",
        "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
        "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
        "    response = client.embeddings.create(\n",
        "        input=decryption_level,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    decryption_level_embedding = np.array(response.data[0].embedding)\n",
        "    decryption_level_embedding = decryption_level_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(original_level_embedding, decryption_level_embedding)\n",
        "    overall_similarity_score += similarity_score\n",
        "\n",
        "print()\n",
        "print('Mean cosine sim: ', overall_similarity_score / len(enc_dec_pairs))"
      ],
      "metadata": {
        "id": "T68XDoyWJn4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}