{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdQoEgV2676i"
      },
      "outputs": [],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai\n",
        "!curl ipinfo.io\n",
        "!pip install -q google-generativeai\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "!pip install bert_score\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "wMSPCraARaoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rouge import Rouge\n",
        "from bert_score import score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "review_df = pd.read_csv('IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "oWJzWFaU78mC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non-Reusable Encryption & Performance Evaluation"
      ],
      "metadata": {
        "id": "L4fwEv2dRznf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='')\n",
        "\n",
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-4-1106-preview'\n",
        "\n",
        "# Define the system message\n",
        "system_msg = \"Please serve as a binary sentiment classifier on movie reviews.\"\n",
        "\n",
        "right_count = 0\n",
        "compressed_right_count = 0\n",
        "total = 0\n",
        "gemini_review_pairs = []\n",
        "\n",
        "for index, row in review_df.iterrows():\n",
        "\n",
        "    original_prompt = (\n",
        "        f\"Given the following movie review: {row['review']}; \"\n",
        "        f\"Determine the sentiment of the review; Do NOT explain anything, just output positive or negative, in lower case:\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": original_prompt }],\n",
        "            timeout = 1200)\n",
        "\n",
        "    original_pred = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    if row['sentiment'] == original_pred:\n",
        "        right_count += 1\n",
        "\n",
        "    # Perform review encryption\n",
        "    compress_prompt = (\n",
        "        \"Transform each sentnce of the following movie review into a highly condensed, NON-natural language sequence. \"\n",
        "        \"This sequence should be rich in information and capture all the emotional nuances of the review. \"\n",
        "        \"You may use a mix of emojis, emoticons, abbreviated characters, as well as math & logical operators (Ex. '->', '+', '<=', etc.). \"\n",
        "        \"The output should retain meaning for easy LLM understanding. \"\n",
        "        # \"After transformation, generate a brief natural language explaination on how a LLM can interpret it as a movie review. \"\n",
        "        \"Do NOT explain your output!\"\n",
        "        \"Example 1: \\n\"\n",
        "        \"Original Review: \"\n",
        "        \"I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her 'sexy' image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than 'Devil Wears Prada' and more interesting than 'Superman' a great comedy to go see with friends. \\n\"\n",
        "        \"Compressed Review: \"\n",
        "        \"🌡️🔼🕒🎥😄📉📜🔍🎭👍(🍞🔪🤔)🚫🎾2️⃣👏🧩👴🎩❤️🤣🪑10y🚫🤩🧣👩🔽🔥👟👏👥 \\n\\n\"\n",
        "        \"Example 2: \\n\"\n",
        "        \"Original Review: \"\n",
        "        \"This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\"\n",
        "        \"Compressed Review: \"\n",
        "        \"[📺+💡+😀(70's)]->[😐(1990)]->[👎(Today)][✍️⬇️]|[🎭⬇️][🎤+😂] >= [📺+📻][🧠💡↔️🧠👇]\"\n",
        "        f\"Original Review:: {row['review']}\"\n",
        "    )\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    generation_config = genai.GenerationConfig(\n",
        "        stop_sequences = None,\n",
        "        temperature= 1.0,\n",
        "        max_output_tokens = 200,\n",
        "    )\n",
        "\n",
        "    successful = False\n",
        "    while not successful:\n",
        "        try:\n",
        "            response = model.generate_content(contents=compress_prompt, generation_config=generation_config,\n",
        "                                              safety_settings=[\n",
        "                                                  {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                                  {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                                              ])\n",
        "\n",
        "            # Try to assign compressed_review using response.text\n",
        "            compressed_review = response.text\n",
        "            successful = True  # If no error, mark as successful\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}. Retrying...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "    print(row['review'])\n",
        "    print(compressed_review)\n",
        "    print()\n",
        "\n",
        "    sentiment_analysis_prompt = (\n",
        "        \"You are given a movie review presented as a compressed NON-natural language sequence, \"\n",
        "        \"utilizing a mix of abbreviated characters, emojis, emoticons, as well as math & logical operators (Ex. '->', '+', '<=', etc.). \"\n",
        "        \"This sequence encapsulates the emotional content of the original review. \"\n",
        "        \"Analyze the sentiment of the compressed review and ONLY output it as either 'positive' or 'negative', \"\n",
        "        \"without detailing the decoding process or explanations. Below is the compressed review: \\n\\n\"\n",
        "        f\"{compressed_review}\"\n",
        "    )\n",
        "\n",
        "    compressed_completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": sentiment_analysis_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    compressed_pred = compressed_completion.choices[0].message.content\n",
        "\n",
        "    if row['sentiment'] == compressed_pred:\n",
        "        compressed_right_count += 1\n",
        "\n",
        "\n",
        "    # Perform review decryption\n",
        "    decryption_prompt = (\n",
        "        \"Given the following compressed movie review in non-natural language form: \"\n",
        "        f\"{compressed_review} \\n\\n\"\n",
        "        \"Try to decode it into a natural language review; return the decoded review only: \"\n",
        "    )\n",
        "\n",
        "    decryption_completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are to serve as a decrypter for movie reviews represented in emojis, emoticons, abbreviated characters, as well as math & logical operators (Ex. '->', '+', '<=', etc.).\"},\n",
        "                        {\"role\": \"user\", \"content\": decryption_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    decryption_pred = decryption_completion.choices[0].message.content\n",
        "    gemini_review_pairs.append( [row['review'], decryption_pred] )\n",
        "\n",
        "    if total % 10 == 0 or total == review_df.shape[0]:\n",
        "        print(f\"Accuracy: {right_count/total}\")\n",
        "        print(f\"Compressed Accuracy: {compressed_right_count/total}\")\n",
        "        print()\n",
        "\n",
        "    # # If you would like to test for a subset\n",
        "    # if total == 300:\n",
        "    #     break\n"
      ],
      "metadata": {
        "id": "dNji1Oy3Rz5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decryption Robustness Test"
      ],
      "metadata": {
        "id": "vutkh3AUS9OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "from bert_score import score\n",
        "\n",
        "# Initialize ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "# Initialize a dictionary to accumulate scores\n",
        "accumulated_scores = {\"rouge-1\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
        "                      \"rouge-2\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
        "                      \"rouge-l\": {\"f\": 0, \"p\": 0, \"r\": 0}}\n",
        "\n",
        "for i in range( len(gemini_review_pairs) ):\n",
        "    original_review = gemini_review_pairs[i][0]\n",
        "    decryption_review = gemini_review_pairs[i][1]\n",
        "\n",
        "    scores = rouge.get_scores(decryption_review, original_review)[0]\n",
        "\n",
        "    # Accumulate scores\n",
        "    for k, v in scores.items():\n",
        "        for score_type, score_value in v.items():\n",
        "            accumulated_scores[k][score_type] += score_value\n",
        "\n",
        "\n",
        "# Calculate average scores\n",
        "num_pairs = len(gemini_review_pairs)\n",
        "average_scores = {k: {score_type: score_value / num_pairs for score_type, score_value in v.items()} for k, v in accumulated_scores.items()}\n",
        "\n",
        "# Print average scores, rounded to 4 decimal places\n",
        "for k, v in average_scores.items():\n",
        "    print(f\"{k}:\")\n",
        "    for score_type, score_value in v.items():\n",
        "        print(f\"  {score_type}: {round(score_value, 4)}\")\n"
      ],
      "metadata": {
        "id": "-YVCCwxiDA2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "overall_similarity_score = 0\n",
        "for i in range( len(gemini_review_pairs) ):\n",
        "    original_review = gemini_review_pairs[i][0]\n",
        "    decryption_review = gemini_review_pairs[i][1]\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        input=original_review,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    original_review_embedding = np.array(response.data[0].embedding)\n",
        "    original_review_embedding = original_review_embedding.reshape(1, -1)\n",
        "\n",
        "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
        "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
        "    response = client.embeddings.create(\n",
        "        input=decryption_review,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    decryption_review_embedding = np.array(response.data[0].embedding)\n",
        "    decryption_review_embedding = decryption_review_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(original_review_embedding, decryption_review_embedding)\n",
        "    overall_similarity_score += similarity_score\n",
        "\n",
        "print()\n",
        "print('Mean cosine sim: ', overall_similarity_score / len(gemini_review_pairs))"
      ],
      "metadata": {
        "id": "gfHudYomJXwp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}