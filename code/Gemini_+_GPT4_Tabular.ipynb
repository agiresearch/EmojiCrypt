{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LjYgGyl9anv"
      },
      "outputs": [],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai\n",
        "!curl ipinfo.io\n",
        "!pip install -q google-generativeai\n",
        "!pip install rouge\n",
        "!pip install nltk\n",
        "!pip install bert_score\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "d3_ogHvaoMdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "census_df = pd.read_csv('census_small.csv', header = None)\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
        "                'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Assign the column names to the DataFrame\n",
        "census_df.columns = column_names\n",
        "census_df.fillna('Unknown')\n",
        "\n",
        "print( census_df['income'].unique() )\n",
        "census_df['income'] = census_df['income'].replace(' <=50K', 'no')\n",
        "census_df['income'] = census_df['income'].replace(' >50K', 'yes')\n",
        "census_df.drop(columns=['fnlwgt', 'education-num'], inplace=True)\n",
        "print( census_df['income'].unique() )"
      ],
      "metadata": {
        "id": "LuS2fJPj9i6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reusable Encryption (on feature levels)"
      ],
      "metadata": {
        "id": "kkyp6Y5BoRJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='')\n",
        "\n",
        "# Assuming census_df and genai.GenerativeModel are properly defined\n",
        "feature_level_dict = {}\n",
        "for column in census_df.columns[:-1]:  # Exclude the discretized column for this part\n",
        "    unique_values = census_df[column].unique()\n",
        "    for value in unique_values:\n",
        "        feature_level_to_convert = f\"Feature: {column}, Value: {value}\"\n",
        "        if feature_level_to_convert not in feature_level_dict:\n",
        "\n",
        "            success = False  # Flag to indicate success of the operation\n",
        "\n",
        "            while not success:\n",
        "                try:\n",
        "                    print(feature_level_to_convert)\n",
        "\n",
        "                    revised_prompt = (\n",
        "                        f\"Analyze the feature and value: {feature_level_to_convert}. \"\n",
        "                        \"Create a sequence using NON-natural language elements to depict the feature-value pair provided above. \"\n",
        "                        \"Key guidelines: \"\n",
        "                        \"- Avoid directly mentioning the feature value in the sequence! Instead, use symbolic representations to represent the feature value precisely! \"\n",
        "                        \"- Utilize a mix of abbreviated characters, emojis, emoticons, and logical/math operators (e.g., '->', '+', '<='). \"\n",
        "                        \"- Aim for clarity and simplicity, ensuring the sequence is interpretable by advanced LLMs. Example: if feature and value = 'Feature: age, Value: 39', then the LLM need to be able to recognize it after sequence conversion.\"\n",
        "                        \"- Present your sequence as a single line, optimizing for diversity in symbols while minimizing token usage. \"\n",
        "                        \"Example (for illustration ONLY): For 'Feature: age, Value: 39', you might write: ðŸ‘©. Also, human readers should NOT be able to interpret the generated sequence!\" )\n",
        "\n",
        "                    model = genai.GenerativeModel('gemini-pro')\n",
        "                    generation_config = genai.GenerationConfig(\n",
        "                        stop_sequences = None,\n",
        "                        temperature= 1.0,\n",
        "                        max_output_tokens = 10,\n",
        "                    )\n",
        "\n",
        "                    response = model.generate_content(contents = revised_prompt, generation_config = generation_config,\n",
        "                                                    safety_settings = [\n",
        "                                {\n",
        "                                    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "                                    \"threshold\": \"BLOCK_NONE\",\n",
        "                                },\n",
        "                                {\n",
        "                                    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "                                    \"threshold\": \"BLOCK_NONE\",\n",
        "                                },\n",
        "                                {\n",
        "                                    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "                                    \"threshold\": \"BLOCK_NONE\",\n",
        "                                },\n",
        "                                {\n",
        "                                    \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "                                    \"threshold\": \"BLOCK_NONE\",\n",
        "                                },\n",
        "                            ], )\n",
        "\n",
        "                    feature_level_dict[feature_level_to_convert] = response.text\n",
        "                    print(response.text)\n",
        "                    print()\n",
        "\n",
        "                    success = True  # Indicate success to exit the while loop\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred: {e}. Retrying...\")\n",
        "                    time.sleep(1)  # Wait a bit before retrying to avoid hammering the server/API\n"
      ],
      "metadata": {
        "id": "rfqmqFStPRX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation"
      ],
      "metadata": {
        "id": "ieBFFUX4o-s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-4-1106-preview'\n",
        "\n",
        "system_msg = \"Please serve as a binary classifier on user income level.\"\n",
        "\n",
        "right_count_pos = 0\n",
        "right_count_neg = 0\n",
        "compressed_right_count_pos = 0\n",
        "compressed_right_count_neg = 0\n",
        "total_pos = 0\n",
        "total_neg = 0\n",
        "total = 0\n",
        "\n",
        "# you may also set range smaller for a subset\n",
        "for i in range( len(census_df) ):\n",
        "    row_series = census_df.iloc[i][:-1]\n",
        "    target = census_df.iloc[i]['income']\n",
        "    # print(target)\n",
        "    overall_feature_levels = ''\n",
        "    converted_feature_levels = ''\n",
        "    # Iterate through the Series and print out 'Feature: xxx, Value: xx' for each item\n",
        "    for feature, value in row_series.items():\n",
        "        feature_level = (f\"Feature: {feature}, Value: {value}\")\n",
        "\n",
        "        overall_feature_levels += feature_level + '; '\n",
        "        converted_feature_levels += (f\"Feature: {feature}, Value: {feature_level_dict[feature_level]}\") + '; '\n",
        "        # print(converted_feature_level)\n",
        "\n",
        "    print(overall_feature_levels)\n",
        "    print(converted_feature_levels)\n",
        "    print()\n",
        "\n",
        "    original_prompt = (\n",
        "        f\"Given the following user description: \\n\\n {overall_feature_levels}; \\n\\n\"\n",
        "        f\"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'yes' or 'no', in lower case:\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": original_prompt }],\n",
        "            timeout = 1200)\n",
        "\n",
        "    original_pred = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    if target == 'yes':\n",
        "        total_pos += 1\n",
        "    else:\n",
        "        total_neg += 1\n",
        "\n",
        "    if target == original_pred:\n",
        "        if (target == 'yes'):\n",
        "            right_count_pos += 1\n",
        "        else:\n",
        "            right_count_neg += 1\n",
        "\n",
        "    census_prompt = (\n",
        "        \"You are given an user description with each feature value presented as a compressed NON-natural language sequence, \"\n",
        "        \"utilizing a mix of abstract & abbreviated characters, emojis, emoticons, as well as math & logical operators. \"\n",
        "        \"This sequence encapsulates the essential information of the user's original feature value. \"\n",
        "        \"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'yes' or 'no', in lower case, \"\n",
        "        \"Below is the compressed user description: \\n\\n\"\n",
        "        f\"{converted_feature_levels}\"\n",
        "    )\n",
        "\n",
        "    compressed_completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": census_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    compressed_pred = compressed_completion.choices[0].message.content\n",
        "\n",
        "    if target == compressed_pred:\n",
        "        if (target == 'yes'):\n",
        "            compressed_right_count_pos += 1\n",
        "        else:\n",
        "            compressed_right_count_neg += 1\n",
        "\n",
        "    if total % 10 == 0 or total == census_df.shape[0]:\n",
        "        print(f\"Accuracy: { (right_count_pos/total_pos) * 0.5 + (right_count_neg/total_neg) * 0.5 }\")\n",
        "        print(f\"Compressed Accuracy: { (compressed_right_count_pos/total_pos) * 0.5 + (compressed_right_count_neg/total_neg) * 0.5 }\")\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "GYSNB3Mo_HH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decryption Robustness Test"
      ],
      "metadata": {
        "id": "z7CYZpVyo5tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_dec_pairs = {}\n",
        "for k,v in feature_level_dict.items():\n",
        "    feature = k.split(', V')[0]\n",
        "\n",
        "    decryption_prompt = f\"Given the {feature}, and the non-natural language sequence: '{v}' that represents a value of the {feature} feature given, please try to decode the value. Return the decoded value only, in lower case and on a new line.\"\n",
        "    print(decryption_prompt)\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please serve as a feature value decrypter for the encrypted value given'},\n",
        "                        {\"role\": \"user\", \"content\": decryption_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    decryption = completion.choices[0].message.content\n",
        "\n",
        "    enc_dec_pairs[k] = feature + \", Value: \" + decryption\n",
        "    print(k, ' ', enc_dec_pairs[k])\n",
        "    print()\n",
        "\n",
        "overall_similarity_score = 0\n",
        "for k, v in enc_dec_pairs.items():\n",
        "    original_level = k.split(', Value: ')[1]\n",
        "    decryption_level = v.split(', Value: ')[1]\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        input=original_level,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    original_level_embedding = np.array(response.data[0].embedding)\n",
        "    original_level_embedding = original_level_embedding.reshape(1, -1)\n",
        "\n",
        "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
        "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
        "    response = client.embeddings.create(\n",
        "        input=decryption_level,\n",
        "        model=\"text-embedding-3-small\",\n",
        "        dimensions = 100,\n",
        "    )\n",
        "    decryption_level_embedding = np.array(response.data[0].embedding)\n",
        "    decryption_level_embedding = decryption_level_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(original_level_embedding, decryption_level_embedding)\n",
        "    overall_similarity_score += similarity_score\n",
        "\n",
        "print()\n",
        "print('Mean cosine sim: ', overall_similarity_score / len(enc_dec_pairs))"
      ],
      "metadata": {
        "id": "nY3-NFRFksQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}